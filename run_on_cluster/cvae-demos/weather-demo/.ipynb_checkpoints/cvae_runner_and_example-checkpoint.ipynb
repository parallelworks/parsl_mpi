{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **CVAE Weather Ensemble Model**\n",
    "\n",
    "This notebook provides examples for working with weather data along with a section to launch online learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "import papermill as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import netCDF4\n",
    "import cartopy\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make needed directories\n",
    "# use -p to make parent directories\n",
    "!mkdir -p gefs_data/converted\n",
    "!mkdir -p model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DVC initialization and storage set up\n",
    "!dvc init --subdir\n",
    "!dvc remote add -d dvcstorage /aws-dvc-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial commit to git\n",
    "!git add .\n",
    "!git commit -m \"loaded dependencies, mkdir -p, DVC init\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Convert Data\n",
    "On my [first Google hit for GEFS](https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast), I clicked on [AWS Open Data Registry for GEFS](https://registry.opendata.aws/noaa-gefs-pds/) and selected [NOAA GEFS Re-forecast](https://registry.opendata.aws/noaa-gefs-reforecast/) which has no useage restrictions.  The [GEFS Re-forecast data documentation](https://noaa-gefs-retrospective.s3.amazonaws.com/Description_of_reforecast_data.pdf) is very clear. The date of the initialization of the re-forecast is in the file name in the format YYYYMMDDHH.  The c00, p01, p02, p03, p04 are the control and perturbation ensemble members (5 total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.get_data import download_file\n",
    "from scripts.get_data import convert_file\n",
    "from scripts.get_data import remove_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pdir = \"./gefs_data\"\n",
    "data_dir = \"./gefs_data/converted/\"\n",
    "model_dir = './model_dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example parameters\n",
    "ex_year = \"2018\"\n",
    "ex_month = \"01\"\n",
    "ex_day = \"01\"\n",
    "ex_ensemble = \"c00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for getting and converting files \n",
    "download_file(ex_year, ex_month, ex_day, ex_ensemble, data_pdir)\n",
    "convert_file(ex_year, ex_month, ex_day, ex_ensemble, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for loading data\n",
    "dataset = netCDF4.Dataset(data_dir + f\"pres_msl_{ex_year}{ex_month}{ex_day}00_{ex_ensemble}.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for simple data access\n",
    "print(dataset) # look at data structure\n",
    "print(dataset.variables.keys())\n",
    "\n",
    "for var in dataset.variables:\n",
    "    print(dataset.variables[var])\n",
    "    # print(dataset.variables[var][:]) # prints actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = plt.axes(projection = cartopy.crs.LambertConformal())\n",
    "\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.add_feature(cartopy.feature.LAKES, alpha = 0.5)\n",
    "ax.add_feature(cartopy.feature.STATES, edgecolor='grey')\n",
    "ax.set_extent([-120, -73, 23, 50])\n",
    "\n",
    "plt.contour(\n",
    "    dataset.variables['lon'][:],     # longitudes\n",
    "    dataset.variables['lat'][:],     # latitudes\n",
    "    dataset.variables['msl'][0,:,:], # actual data\n",
    "    transform = cartopy.crs.PlateCarree()) #, levels=np.arange(30000,110000,20000))\n",
    "\n",
    "plt.title('GEFSv12 SLP 2019 01 10 0000 UTC Cycle')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Online Training\n",
    "\n",
    "*add a note about how datat is randomized, sorted, and stuff*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up example data before executing online session\n",
    "remove_data(data_pdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters for pm -> change the lists to fit your needs\n",
    "years = [\"2000\", \"2001\", \"2002\", \"2003\"]#, \"2004\", \"2005\", \"2006\"] # , \"2007\", \"2008\", \"2009\", \n",
    "         # \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "days = [\"01\", \"10\", \"20\"] # \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \n",
    "        # \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for y in years:\n",
    "    for d in days:\n",
    "            pm.execute_notebook(\n",
    "                'cvae_training.ipynb',\n",
    "                'cvae_log.ipynb',\n",
    "                parameters = dict(year = y, day = d),\n",
    "                kernel_name = 'cvae_env' # this should be changed to whatever you chose <NAME> to be during environment set up\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try different filter sizes\n",
    "# Aim for large initial filter > 200km scale (about 10)\n",
    "# Aim for some, but minimal overlap in initial filter.\n",
    "\n",
    "# Aim for smallish second filter, but still try to reduce dimensionality\n",
    "# to make dense network tractable later. No overlap (but no good\n",
    "# reason why this is).\n",
    "\n",
    "# ----------------------Input: 721 x 1440--------------\n",
    "\n",
    "# For Lat = 721,\n",
    "# K = 11 -> K_radius = 5.0 -> S = 9 -> H_out = 79.0\n",
    "\n",
    "# For Lon = 1440,\n",
    "# K = 11 -> K_radius = 5.0 -> S = 10 -> H_out = 143.0\n",
    "\n",
    "# -----------------------Layer1: 79 x 143----------------\n",
    "\n",
    "# For Lat = 79,\n",
    "# K = 5 -> K_radius = 2.0 -> S = 5 -> H_out = 15.0\n",
    "\n",
    "# For Lon = 143,\n",
    "# K = 9 -> K_radius = 4.0 -> S = 9 -> H_out = 15.0\n",
    "\n",
    "'''\n",
    "H_in = 1440\n",
    "P = 0\n",
    "K_list = [3, 5, 7, 9, 11, 13, 15]                    # Kernel size\n",
    "S_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] # Stride\n",
    "\n",
    "for K in K_list:\n",
    "    for S in S_list:\n",
    "        K_radius = np.floor(np.divide(K, 2))   # Half width of number of points around the central point\n",
    "        K_diameter = K - 1                     # Number of points around the central point, ASSUMES K = ODD\n",
    "        # S = K                                # S = K is stride necessary to have non-overlapping filters\n",
    "        print('K = ' + str(K) + ' -> K_radius = ' + str(K_radius) + ' -> S = ' + str(S) + ' -> H_out = ' + str((H_in + (2 * P) - K_diameter) / S))\n",
    "    print('')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display a grid of sampled digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if latent_dim == 2:\n",
    "#     plot_latent_space(vae, path = os.path.join(model_dir, 'latent_space.png'))\n",
    "\n",
    "# # Generating new images\n",
    "# codings = tf.random.normal(shape = [12, latent_dim])\n",
    "# images = vae.decoder(codings).numpy()\n",
    "# plot_images(images, 3, 4, path = os.path.join(model_dir, 'generated.png'))\n",
    "\n",
    "# # Semantic interpolation\n",
    "# codings_grid = tf.reshape(codings, [1, 3, 4, latent_dim])\n",
    "# larger_grid = tf.image.resize(codings_grid, size = [5, 7])\n",
    "# interpolated_codings = tf.reshape(larger_grid, [-1, latent_dim])\n",
    "# images = vae.decoder(interpolated_codings).numpy()\n",
    "# plot_images(images, 5, 7, path = os.path.join(model_dir, 'interpolated.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display how the latent space clusters different digit classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_label_clusters(vae, data, labels):\n",
    "#     # display a 2D plot of the digit classes in the latent space\n",
    "#     z_mean, _, _ = vae.encoder.predict(data)\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel(\"z[0]\")\n",
    "#     plt.ylabel(\"z[1]\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# (x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "# x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "# plot_label_clusters(vae, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvae_env]",
   "language": "python",
   "name": "conda-env-cvae_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
