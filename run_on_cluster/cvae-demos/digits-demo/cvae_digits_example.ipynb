{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af3de73-569a-46b0-8fe9-2e1658aea2a3",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder Digits Example\n",
    "\n",
    "Check the README for an introduction to the project and how to get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bf264-4ddd-47d4-851e-0e31b2fbd98b",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc2c80-8eb8-46d0-888c-b70d26e71f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "# ml dependencies\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras import layers\n",
    "\n",
    "# mlflow dependencies\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dea6e9-69e5-4cee-a546-a9db7792978b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the model directory for saving outputs\n",
    "model_dir = './model-dir'\n",
    "os.makedirs(model_dir, exist_ok = True)\n",
    "\n",
    "env_name = \"digits_env\" # <name of your env>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c11e1-f566-4353-b220-f50d367cc310",
   "metadata": {},
   "source": [
    "## Create the ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9583330-6383-440f-acc5-ce631cf9e27a",
   "metadata": {},
   "source": [
    "### Create sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013491ac-f39f-44bb-9883-7a6cfcac1f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = ops.shape(z_mean)[0]\n",
    "        dim = ops.shape(z_mean)[1]\n",
    "        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
    "        return z_mean + ops.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4536fc-e359-49fb-bc52-54b9ff244d46",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70b33c-f2bd-41fb-83f4-90ac1c4afef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91004269-b7a7-4d19-8812-729cd8366b9e",
   "metadata": {},
   "source": [
    "### Build the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab93526-4805-4a62-95a8-3dbceb47950e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85405b6c-a092-49ad-9358-5e0c38622c59",
   "metadata": {},
   "source": [
    "### Define the VAE as a `Model` with a custom `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ef055-a698-4458-8b30-8671d3975195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = ops.mean(\n",
    "                ops.sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction),\n",
    "                    axis=(1, 2),\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943c16f-dff8-479e-a7ee-dc38cb68249c",
   "metadata": {},
   "source": [
    "## DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1dc0f-939e-41dd-a9a6-091911a598a2",
   "metadata": {},
   "source": [
    "In the lines below, the `&&` symbol is used multiple times. This symbol is originally a logical operator (the command on the right will only run if the command on the left executes successfully). However, when using `!` in a Jupyter notebook, the Linux commands are executed within the directory where the notebook is currently located. This behavior prevents commands from being run in separate directories if `!cd` is on its own line. Using `&&` ensures that the `dvc` commands are executed within the `dvc` submodule directory, without affecting the repository where the notebook resides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ae770-6a77-469b-b7ef-88698007156b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dvc_repo_link = \"git@github.com:oobielodan/digits_dvc.git\" # <ssh link to the repo you set aside for dvc>\n",
    "dvc_storage = \"/demo-bucket\" # <complete path to the mounted storage you have set up for dvc>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c4ccb-6144-4ac4-a692-c04ec4ef2ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grab your dvc repository -> the --force flag allows for this to still run if the submodule had already been created at a prior time\n",
    "!git submodule add --force \"{dvc_repo_link}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e481ef0-3ceb-44e6-9777-4a588b8a3921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dvc_repo = \"digits_dvc\" # <name of the repository/submodule you just added for dvc> -> should appear as a folder in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e2ab8-16cd-4175-ab32-a501bbdfcd59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DVC initialization and storage set up\n",
    "!cd \"{dvc_repo}\" && dvc init\n",
    "!cd \"{dvc_repo}\" && dvc remote add -d dvcstorage \"{dvc_storage}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711066f-c8b6-46e2-9cd4-c90be29c053f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial commit to git\n",
    "!cd \"{dvc_repo}\" && git add .\n",
    "!cd \"{dvc_repo}\" && git commit -m \"loaded dependencies, mkdir -p, DVC init\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b6282-650d-4e92-9537-811e4e09754d",
   "metadata": {},
   "source": [
    "## MLFlow\n",
    "MLflow is designed to help simplify the ML workflow, assisting users throughout the various stages of development and deployment. In this notebook, we use its ... capabilities to ... Documentation and more information can be found at [the MLFlow website](https://mlflow.org/docs/latest/index.html).\n",
    "\n",
    "\n",
    "To get started with MLflow, run `mlflow server --host 127.0.0.1 --port 8080` in the command line. The `mlflow server` command needs to run in the background and therefore cannot be executed directly in a Jupyter notebook, as each cell must complete execution before the next one can run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6018ac9f-99fe-438d-8942-8285ced96f03",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "*If you used a different host and/or port during initialization, make sure to update the following URIs accordingly.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10acc3-348f-4437-9767-b6f0d50924b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utilize and set up the initialized server for tracking \n",
    "client = MlflowClient(tracking_uri = \"http://127.0.0.1:8080\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87c393-fc86-437e-876f-f991f38bd1f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view the metadata associated with all the experiments that are currently on the server. \n",
    "all_experiments = client.search_experiments()\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15316ea-3e62-407f-9a8b-766c5d46d815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for accessing elements from returned collections of experiments\n",
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Default\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b8766-424d-40b2-bee4-5cd60ba3b329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# working on getting the server to display in the notebook --------------------------------------\n",
    "# !curl http://127.0.0.1:8080\n",
    "# %%javascript\n",
    "# alert(\"JavaScript is working!\");\n",
    "# from IPython.display import IFrame\n",
    "# IFrame(\"http://127.0.0.1:8080\", 900,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c160f-45da-42be-9ed3-5385510e89e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment 1\n",
    "In Experiment 1, we train the Digit CVAE model on multiple datasets. To create these datasets, we split the original dataset into five equal, randomized parts. After each training session, we save the weights and use them as the starting point for retraining the model on the next dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a09d3f-a2a4-49fe-b97c-e0bcfda96323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# provide an experiment description that will appear in the UI\n",
    "experiment1_description = (\n",
    "    \"This is the digits forecasting project.\"\n",
    "    \"This experiment contains the digit model for randomized numbers (0-9) trained separately.\"\n",
    ")\n",
    "\n",
    "# provide searchable tags for the experiment\n",
    "experiment1_tags = {\n",
    "    \"project_name\": \"digit-forecasting\",\n",
    "    \"model_type\": \"randomzied\",\n",
    "    \"team\": \"digit-ml\",\n",
    "    \"project_quarter\": \"Q3-2024\",\n",
    "    \"mlflow.note.content\": experiment1_description,\n",
    "}\n",
    "\n",
    "# create the experiment and give it a unique name\n",
    "digit_experiment1 = client.create_experiment(\n",
    "    name=\"Randomize_Model\", tags=experiment1_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8264adfb-09ee-4218-9c30-421d3ac41e23",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "In Experiment 2, we train the Digit CVAE model on all digit samples simultaneously, without any subsequent retraining using the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5258b2-2c71-475d-83fd-d597cfc05454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# provide an experiment description that will appear in the UI\n",
    "experiment2_description = (\n",
    "    \"This is the digits forecasting project.\"\n",
    "    \"This experiment contains the digit model for numbers (0-9) trained all together.\"\n",
    ")\n",
    "\n",
    "# provide searchable tags for the experiment\n",
    "experiment2_tags = {\n",
    "    \"project_name\": \"digit-forecasting\",\n",
    "    \"model_type\": \"all digits\",\n",
    "    \"team\": \"digit-ml\",\n",
    "    \"project_quarter\": \"Q3-2024\",\n",
    "    \"mlflow.note.content\": experiment2_description,\n",
    "}\n",
    "\n",
    "# create the experiment and give it a unique name\n",
    "digit_experiment2 = client.create_experiment(\n",
    "    name=\"Together_Model\", tags=experiment2_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de39b5-391a-4305-a317-e15c14a8c4a5",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "In Experiment 3, we revisit the approach used in Experiment 1 - initializing the model with the weights from a previous training session and retraining it from there. However in this experiment, we train the Digit CVAE model sequentially on each of the 10 digits (0â€“9), one digit at a time. After each training session, we save the weights and use them to retrain the model on the next digit. This approach induces a 'forgetting' effect, where the model gradually loses its ability to recognize previous digits with each subsequent training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e4009-d290-4053-93e9-b665b04c5aea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# provide an experiment description that will appear in the UI\n",
    "experiment3_description = (\n",
    "    \"This is the digits forecasting project.\"\n",
    "    \"This experiment contains the digit model for each of the numbers (0-9) trained separately.\"\n",
    ")\n",
    "\n",
    "# provide searchable tags that define characteristics of the runs that will be in this experiment\n",
    "experiment3_tags = {\n",
    "    \"project_name\": \"digit-forecasting\",\n",
    "    \"model_type\": \"sequential\",\n",
    "    \"team\": \"digit-ml\",\n",
    "    \"project_quarter\": \"Q3-2024\",\n",
    "    \"mlflow.note.content\": experiment3_description,\n",
    "}\n",
    "\n",
    "# create the experiment and give it a unique name\n",
    "digit_experiment3 = client.create_experiment(\n",
    "    name=\"Sequenced_Model\", tags=experiment3_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234d529-70a9-4806-a3da-fc55d3564864",
   "metadata": {},
   "source": [
    "### Experiment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db30da-8a05-4e72-b1e2-907bc7ea6631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save each of the experiment's metadata\n",
    "digit_experiment1 = mlflow.set_experiment(\"Randomize_Model\")\n",
    "digit_experiment2 = mlflow.set_experiment(\"Together_Model\")\n",
    "digit_experiment3 = mlflow.set_experiment(\"Sequenced_Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f662b7-a8c8-4ae4-9f60-b6de69e0ddef",
   "metadata": {},
   "source": [
    "## Train the VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c6708-4ea5-45af-8b6c-13406429f4c3",
   "metadata": {},
   "source": [
    "*Make sure that 'vae.weights.h5' does not already exist in the model directory if you want to training from the beginning.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645768a-9b70-4568-8e59-7544678392ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "(x_train, Y_train), (x_test, Y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc6419-1cbc-4261-ac12-92779e526d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True) # stops training early if the validation loss does not improve\n",
    "\n",
    "def train_model(num, model, data, experiment):\n",
    "    if os.path.exists(os.path.join(model_dir, 'vae.weights.h5')): # if the model has already been trained at least once, load that model\n",
    "        model.load_weights(os.path.join(model_dir, 'vae.weights.h5'))\n",
    "    \n",
    "    mlflow.autolog()\n",
    "    \n",
    "    run_name = f\"{num}_test\" # define a run name for this iteration of training\n",
    "    artifact_path = f\"{num}\"  # define an artifact path that the model will be saved to\n",
    "    \n",
    "    # initiate the MLflow run context\n",
    "    with mlflow.start_run(run_name = run_name, experiment_id = experiment) as run:\n",
    "        # mlflow.log_params({\"num\": num}) # log the parameters used for the model fit\n",
    "        # mlflow.log_metrics(history.history) #  log the error metrics that were calculated during validation\n",
    "        # mlflow.keras.save.log_model(model, \"model\") # log an instance of the trained model for later use\n",
    "    \n",
    "        history = model.fit(data, epochs=30, batch_size=128, callbacks = [early_stopping_cb])\n",
    "        model.save_weights(os.path.join(model_dir, 'vae.weights.h5')) # save model weights after training\n",
    "\n",
    "        hist_pd = pd.DataFrame(history.history)\n",
    "        hist_pd.to_csv(os.path.join(model_dir, f'history_{num}.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf688b-97d3-4a20-bc27-dae71d7528dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment 1\n",
    "*How to filter mnist data found here: https://stackoverflow.com/questions/51202181/how-do-i-select-only-a-specific-digit-from-the-mnist-dataset-provided-by-keras*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38582c97-e230-4ac6-a4cd-5518bf02c151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retraining the model n times\n",
    "count = 0\n",
    "n = 5\n",
    "\n",
    "mnist_digits = np.expand_dims(np.concatenate([x_train, x_test], axis=0), -1).astype(\"float32\") / 255\n",
    "\n",
    "for arr in np.array_split(mnist_digits, n):\n",
    "    count += 1\n",
    "    train_model(f\"rand_{count}\", vae, arr, digit_experiment3.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc99efc-4727-4904-ab3a-2bb9df539125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add model 1 to dvc \n",
    "!cp ./\"{model_dir}\"/vae.weights.h5 \"{dvc_repo}\"/experiment_1.weights.h5\n",
    "!sh dvcgit.sh experiment_1.weights.h5 \"digit experiment 1\" \"{dvc_repo}\" \"{env_name}\"\n",
    "\n",
    "!rm \"{dvc_storage}\"/experiment_1.weights.h5\n",
    "!rm ./\"{model_dir}\"/vae.weights.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade80f16-6a1e-4e26-b4ce-77314d6fff91",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8849863-fcf5-46dd-997b-78a245dc0e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train all numbers at the same time\n",
    "train_model(\"all\", vae, mnist_digits, digit_experiment2.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22343e08-f3c6-4fb8-aee5-7a5e24cca01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add model 2 to dvc \n",
    "!cp ./\"{model_dir}\"/vae.weights.h5 \"{dvc_repo}\"/experiment_2.weights.h5\n",
    "!sh dvcgit.sh experiment_2.weights.h5 \"digit experiment 2\" \"{dvc_repo}\" \"{env_name}\"\n",
    "\n",
    "!rm \"{dvc_repo}\"/experiment_2.weights.h5\n",
    "!rm ./\"{model_dir}\"/vae.weights.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7acce-d93a-4724-9dfa-4b970b969414",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7662d9d-9844-4f16-8a90-7c4642675abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training one number at a time\n",
    "for num in np.arange(10):\n",
    "    train_filter = np.where(Y_train == num)\n",
    "    test_filter = np.where(Y_test == num)\n",
    "    \n",
    "    x_trn = x_train[train_filter]\n",
    "    x_tst = x_test[test_filter]\n",
    "    \n",
    "    mnist_digits = np.expand_dims(np.concatenate([x_trn, x_tst], axis=0), -1).astype(\"float32\") / 255\n",
    "    train_model(num, vae, mnist_digits, digit_experiment1.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea85634-da45-498e-98fa-46f413516499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add model 3 to dvc \n",
    "!cp ./\"{model_dir}\"/vae.weights.h5 \"{dvc_repo}\"/experiment_3.weights.h5\n",
    "!sh dvcgit.sh experiment_3.weights.h5 \"digit experiment 3\" \"{dvc_repo}\" \"{env_name}\"\n",
    "\n",
    "!rm \"{dvc_repo}\"/experiment_3.weights.h5\n",
    "!rm ./\"{model_dir}\"/vae.weights.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35ce03-037f-4f63-98aa-ef411029326f",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------\n",
    "*`dvcgit.sh` is a script used for dvc and git tracking. The correct call is as follows (all arguments are required):* `sh dvcgit.sh <file_name> <commit_message> <dvc_repo_name> <conda_env_name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494fca6-d4b7-4ef3-91a5-4f1422526fd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display a grid of reconstructed digits in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d63bff-e2c6-40a1-a8f8-d375b008557e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample, verbose=0)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc89d55-5962-463f-ab7f-f0332e2e3430",
   "metadata": {},
   "source": [
    "## Display how the latent space clusters digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dabfbc-7024-4831-8432-6682c42dab7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data, verbose=0)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "plot_label_clusters(vae, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:digits_env]",
   "language": "python",
   "name": "conda-env-digits_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
