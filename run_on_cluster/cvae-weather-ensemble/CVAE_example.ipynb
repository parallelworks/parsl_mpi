{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Demo using CVAE on CORE2 data**\n",
    "This is based on an example from Keras.io by fchollet.  Please see last cell for original code and links.\n",
    "\n",
    "# Conda env Setup\n",
    "The following is the list steps needed to be taken in order to set up a correct conda environment for running this notebook.\n",
    "\n",
    "**Create Environment:**\n",
    "```bash\n",
    "source ~/pw/.miniconda3c/etc/profile.d/conda.sh\n",
    "conda create --name NAME python=3.9\n",
    "conda activate NAME\n",
    "```\n",
    "\n",
    "**Install Pacakages:** \n",
    "\n",
    "The following packages need to be installed on top of a typical base Conda env. Install the packages in the following order so the environment solves correctly:\n",
    "```bash\n",
    "conda install -y -c conda-forge tensorflow\n",
    "conda install -y -c conda-forge netCDF4          # For reading nc files\n",
    "conda install -y -c conda-forge cartopy          # For making maps\n",
    "conda install -y -c conda-forge matplotlib\n",
    "conda install -y -c conda-forge pandas\n",
    "conda install -y -c conda-forge scikit-learn\n",
    "conda install -y -c conda-forge papermill\n",
    "conda install -y -c conda-forge cdo              # For converting grib to nc\n",
    "```\n",
    "**Connect Notebook to Environment:**\n",
    "```bash\n",
    "conda install -y ipykernel\n",
    "conda install -y requests\n",
    "conda install -y -c anaconda jinja2\n",
    "python -m ipykernel install --user --name=NAME --display-name \"Python (NAME)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "import papermill as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import netCDF4\n",
    "import cartopy\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make needed directories\n",
    "!mkdir gefs_data\n",
    "!mkdir gefs_data/converted\n",
    "\n",
    "data_prefix = \"./gefs_data\"\n",
    "data_dir = \"./gefs_data/converted/\" # change to match your own directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Convert Data\n",
    "On my [first Google hit for GEFS](https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast), I clicked on [AWS Open Data Registry for GEFS](https://registry.opendata.aws/noaa-gefs-pds/) and selected [NOAA GEFS Re-forecast](https://registry.opendata.aws/noaa-gefs-reforecast/) which has no useage restrictions.  The [GEFS Re-forecast data documentation](https://noaa-gefs-retrospective.s3.amazonaws.com/Description_of_reforecast_data.pdf) is very clear and we're going to download two files, 57 MB each.  The date of the initialization of the re-forecast is in the file name in the format YYYYMMDDHH.  The c00, p01, p02, p03, p04 are the control and perturbation ensemble members (5 total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data download\n",
    "def get_data(year, month, day, ensembles):\n",
    "    num_files = 0\n",
    "    \n",
    "    for ensemble in ensembles:\n",
    "        if f'pres_msl_{year}{month}{day}00_{ensemble}.grib2' not in os.listdir(data_prefix):\n",
    "            !wget -q -P {data_prefix} https://noaa-gefs-retrospective.s3.amazonaws.com/GEFSv12/reforecast/{year}/{year}{month}{day}00/{ensemble}/Days%3A1-10/pres_msl_{year}{month}{day}00_{ensemble}.grib2\n",
    "        \n",
    "        if f'pres_msl_{year}{month}{day}00_{ensemble}.grib2' in os.listdir(data_prefix):\n",
    "            num_files += 1\n",
    "            \n",
    "    return num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete all files\n",
    "def remove_data():\n",
    "    !find {data_prefix} -type f -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for getting and converting files \n",
    "num_files = get_data(\"2018\", \"01\", \"01\", [\"c00\"])\n",
    "!csh batch_grib2nc.csh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for loading data\n",
    "dataset = netCDF4.Dataset(data_dir + \"pres_msl_2018010100_c00.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for simple data access\n",
    "print(dataset) # look at data structure\n",
    "print(dataset.variables.keys())\n",
    "\n",
    "for var in dataset.variables:\n",
    "    print(dataset.variables[var])\n",
    "    # print(dataset.variables[var][:]) # prints actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = plt.axes(projection = cartopy.crs.LambertConformal())\n",
    "\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.add_feature(cartopy.feature.LAKES, alpha = 0.5)\n",
    "ax.add_feature(cartopy.feature.STATES, edgecolor='grey')\n",
    "ax.set_extent([-120, -73, 23, 50])\n",
    "\n",
    "plt.contour(\n",
    "    dataset.variables['lon'][:],     # longitudes\n",
    "    dataset.variables['lat'][:],     # latitudes\n",
    "    dataset.variables['msl'][0,:,:], # actual data\n",
    "    transform = cartopy.crs.PlateCarree()) #, levels=np.arange(30000,110000,20000))\n",
    "\n",
    "plt.title('GEFSv12 SLP 2019 01 10 0000 UTC Cycle')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters for pm -> change the lists to fit your needs\n",
    "years = [\"2018\"] #, \"2019\", \"2020\"]\n",
    "months = [\"07\", \"08\"] \n",
    "days = [\"01\", \"02\"] #, \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \n",
    "        #\"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\"] # forecasts are 10 days long, so (01, 10, 20) provides converage of whole year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for y in years:\n",
    "    for m in months:\n",
    "        for d in days:\n",
    "            pm.execute_notebook(\n",
    "                'CVAE_training.ipynb',\n",
    "                'CVAE_log.ipynb',\n",
    "                parameters = dict(year = y, month = m, day = d),\n",
    "                kernel_name = 'cvae_env'\n",
    "                \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try different filter sizes\n",
    "# Aim for large initial filter > 200km scale (about 10)\n",
    "# Aim for some, but minimal overlap in initial filter.\n",
    "\n",
    "# Aim for smallish second filter, but still try to reduce dimensionality\n",
    "# to make dense network tractable later. No overlap (but no good\n",
    "# reason why this is).\n",
    "\n",
    "# ----------------------Input: 721 x 1440--------------\n",
    "\n",
    "# For Lat = 721,\n",
    "# K = 11 -> K_radius = 5.0 -> S = 9 -> H_out = 79.0\n",
    "\n",
    "# For Lon = 1440,\n",
    "# K = 11 -> K_radius = 5.0 -> S = 10 -> H_out = 143.0\n",
    "\n",
    "# -----------------------Layer1: 79 x 143----------------\n",
    "\n",
    "# For Lat = 79,\n",
    "# K = 5 -> K_radius = 2.0 -> S = 5 -> H_out = 15.0\n",
    "\n",
    "# For Lon = 143,\n",
    "# K = 9 -> K_radius = 4.0 -> S = 9 -> H_out = 15.0\n",
    "\n",
    "'''\n",
    "H_in = 1440\n",
    "P = 0\n",
    "K_list = [3, 5, 7, 9, 11, 13, 15]                    # Kernel size\n",
    "S_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] # Stride\n",
    "\n",
    "for K in K_list:\n",
    "    for S in S_list:\n",
    "        K_radius = np.floor(np.divide(K, 2))   # Half width of number of points around the central point\n",
    "        K_diameter = K - 1                     # Number of points around the central point, ASSUMES K = ODD\n",
    "        # S = K                                # S = K is stride necessary to have non-overlapping filters\n",
    "        print('K = ' + str(K) + ' -> K_radius = ' + str(K_radius) + ' -> S = ' + str(S) + ' -> H_out = ' + str((H_in + (2 * P) - K_diameter) / S))\n",
    "    print('')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display a grid of sampled digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if latent_dim == 2:\n",
    "#     plot_latent_space(vae, path = os.path.join(model_dir, 'latent_space.png'))\n",
    "\n",
    "# # Generating new images\n",
    "# codings = tf.random.normal(shape = [12, latent_dim])\n",
    "# images = vae.decoder(codings).numpy()\n",
    "# plot_images(images, 3, 4, path = os.path.join(model_dir, 'generated.png'))\n",
    "\n",
    "# # Semantic interpolation\n",
    "# codings_grid = tf.reshape(codings, [1, 3, 4, latent_dim])\n",
    "# larger_grid = tf.image.resize(codings_grid, size = [5, 7])\n",
    "# interpolated_codings = tf.reshape(larger_grid, [-1, latent_dim])\n",
    "# images = vae.decoder(interpolated_codings).numpy()\n",
    "# plot_images(images, 5, 7, path = os.path.join(model_dir, 'interpolated.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display how the latent space clusters different digit classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_label_clusters(vae, data, labels):\n",
    "#     # display a 2D plot of the digit classes in the latent space\n",
    "#     z_mean, _, _ = vae.encoder.predict(data)\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel(\"z[0]\")\n",
    "#     plt.ylabel(\"z[1]\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# (x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "# x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "# plot_label_clusters(vae, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvae_env]",
   "language": "python",
   "name": "conda-env-cvae_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
