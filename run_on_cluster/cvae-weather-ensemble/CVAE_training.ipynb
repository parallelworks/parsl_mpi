{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6226ca5-0869-4973-8369-3469cbdff43c",
   "metadata": {},
   "source": [
    "# **CVAE_training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094dca89-dffa-4a56-8263-371fb372a2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "import papermill as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import netCDF4\n",
    "import cartopy\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8b533-cdaa-4efd-938b-ef1d5a84338e",
   "metadata": {},
   "source": [
    "# Download and Convert Data\n",
    "On my [first Google hit for GEFS](https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast), I clicked on [AWS Open Data Registry for GEFS](https://registry.opendata.aws/noaa-gefs-pds/) and selected [NOAA GEFS Re-forecast](https://registry.opendata.aws/noaa-gefs-reforecast/) which has no useage restrictions.  The [GEFS Re-forecast data documentation](https://noaa-gefs-retrospective.s3.amazonaws.com/Description_of_reforecast_data.pdf) is very clear and we're going to download two files, 57 MB each.  The date of the initialization of the re-forecast is in the file name in the format YYYYMMDDHH.  The c00, p01, p02, p03, p04 are the control and perturbation ensemble members (5 total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08e8b0-f9fa-40b9-852b-8650e681cff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_prefix = \"./gefs_data\"\n",
    "data_dir = \"./gefs_data/converted/\" # change to match your own directory\n",
    "\n",
    "# data download\n",
    "def get_data(year, month, day, ensembles):\n",
    "    num_files = 0\n",
    "    \n",
    "    for ensemble in ensembles:\n",
    "        if f'pres_msl_{year}{month}{day}00_{ensemble}.grib2' not in os.listdir(data_prefix):\n",
    "            !wget -q -P {data_prefix} https://noaa-gefs-retrospective.s3.amazonaws.com/GEFSv12/reforecast/{year}/{year}{month}{day}00/{ensemble}/Days%3A1-10/pres_msl_{year}{month}{day}00_{ensemble}.grib2\n",
    "        \n",
    "        if f'pres_msl_{year}{month}{day}00_{ensemble}.grib2' in os.listdir(data_prefix):\n",
    "            num_files += 1\n",
    "            \n",
    "    return num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4403c-9c45-4129-902b-93ebfe9749e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete all files\n",
    "def remove_data():\n",
    "    !find {data_prefix} -type f -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ebb2a-bc7b-4f52-98d3-ec85c51c7a5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Neural Network Design\n",
    "\n",
    "We need to get to a small latent space. Conv2D networks are good because they help reduce the number of connections in a network in a meaningful way.  I'm using terms as defined in [this definition of conv2D](https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148).\n",
    "\n",
    "**Definitions:**\n",
    "K -> kernel size;\n",
    "P -> padding;\n",
    "S -> stride;\n",
    "D -> Dilation;\n",
    "G -> Groups\n",
    "\n",
    "**Filter options:**\n",
    "Longitude is easy because it is large and even, so as long as you have an even stride, you get integer results when dividing.\n",
    "e.g. lon 9: stride 4, lat 7: stride 5\n",
    "\n",
    "- Latitude - whole numbers occurr for P = 2 & K = 3 or K = 11.\n",
    "- 11 grid points * 0.25 deg * 100 km/deg = 275 km filter window (a good scale for weather)\n",
    "- 9 grid points * 0.25 deg * 100 km/deg = 225 km\n",
    "- Longitude - whole numbers occur for P = 0 & K = 11 (nice match with Latitude), P = 1 & K = 3 or 13, P = 2 & K = 5.\n",
    "\n",
    "For a 5 x 7 filter with 3 stride (no overlap) and no padding:\n",
    "- lat: (721 - 4) / 3 = 239 possible steps (good whole number!)\n",
    "- lon: (1440 - 4) / 3 = 478.6666 possible steps\n",
    "\n",
    "## Load and Preprocess Training Data:\n",
    "The standard way of manipulating arrays in Conv2D layers in TF is to use arrays in the shape:\n",
    "`batch_size,  height, width, channels = data.shape`\n",
    "In our case, the the `batch_size` is the number of image frames (i.e. separate samples or rows in a `.csv` file), the `height` and `width` define the size of the image frame in number of pixels, and the `channels` are the number of layers in the frames.  Typically, channels are color layers (e.g. RGB or CMYK) but in our case, we could use different metereological variables.  However, for this first experiment, **we only need one channel** because we're only going to use mean sea level pressure (msl).\n",
    "\n",
    "## Build the Encoder:\n",
    "GFS grids I have available here are at 0.25 degree resolution.  I'm doing this as a \"worst case\" scenario since there are also 0.5 and 1.0 degree grids with lower resolution but I can't find that data quickly and don't know what's available.\n",
    "\n",
    "These 0.25 degree grids are 721 x 1440.\n",
    "Each forecast file is 3 hourly for 10 days = 8 steps/forecast * 10 days = 80 \"frames\"\n",
    "This demo is only using two forecasts from the control ensemble\n",
    "(one launched Jan 01, 2019 and one launched Jan 02, 2019) -> this is only \n",
    "a small subset of the variability possible in the model.\n",
    "\n",
    "This particular data set spans 2000-2019 and there are 5 ensemble members.\n",
    "\n",
    "## Build the Decoder:\n",
    "With the 11 x 11 and 5 x 5 filters, non-overlapping stride, applied here, we have a final \"image\" size of 14 x 27 and 64 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0144303-f1c9-4220-8178-3988d707688c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim):\n",
    "    encoder_inputs = keras.Input(shape=(721, 1440, 1))\n",
    "    \n",
    "    x = layers.Conv2D(32, 11, activation = \"relu\", strides = [9, 10], padding = \"valid\")(encoder_inputs)\n",
    "    x = layers.Conv2D(64, [5,9], activation = \"relu\", strides = [5, 9], padding = \"valid\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    \n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    \n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name = \"encoder\")\n",
    "    \n",
    "    print(encoder.summary())\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim):\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(15 * 15 * 64, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((15, 15, 64))(x)\n",
    "    # FIXME - there is something wrong here, but at least there is a pattern.\n",
    "    # Using output_padding as a fudge factor -> it may be that there is exactly\n",
    "    # one \"missing\" filter stamp/convolution because for both Conv2DTranspose\n",
    "    # operations, output_padding is set to maximum it could be in both dims\n",
    "    # (i.e. exactly one less than the stride of each filter).\n",
    "    x = layers.Conv2DTranspose(64, [5, 9], activation = \"relu\", strides = [5,9], padding = \"valid\", output_padding = [4, 8])(x)\n",
    "    x = layers.Conv2DTranspose(32, 11, activation = \"relu\", strides = [9,10], padding = \"valid\", output_padding = [8, 9])(x)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1, 3, activation = \"sigmoid\", padding = \"same\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name = \"decoder\")\n",
    "    \n",
    "    print(decoder.summary())\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name = \"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name = \"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name = \"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            # FIXME: Normalize loss with the number of features (28 * 28)\n",
    "            n_features = 28 * 28\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis = (1, 2)\n",
    "                )\n",
    "            ) / n_features\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis = 1)) / n_features\n",
    "            total_loss = (reconstruction_loss + kl_loss)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    # Needed to validate (validation loss) and to evaluate\n",
    "    def test_step(self, data):\n",
    "        if type(data) == tuple:\n",
    "            data, _ = data\n",
    "            \n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        # FIXME: Normalize loss with the number of features (28 * 28)\n",
    "        n_features = 28 * 28\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction), axis = (1, 2)\n",
    "            )\n",
    "        ) / n_features\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis = 1)) / n_features\n",
    "        total_loss = (reconstruction_loss + kl_loss)\n",
    "        # grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        # self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f638f-42a9-4d44-8f31-c6c42017a6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, X_test, X_valid, date, vae):\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True) # stops training early if the validation loss does not improve\n",
    "    \n",
    "    if os.path.exists(model_dir + '/model/saved_model'): # if the model is already saved, load that model\n",
    "        vae = tf.saved_model.load(model_dir + '/model')\n",
    "    \n",
    "    # if os.path.exists(os.path.join(model_dir, 'vae.weights.h5')): # if the model has already been trained at least once, load that model\n",
    "    #     vae.load_weights(os.path.join(model_dir, 'vae.weights.h5'))\n",
    "\n",
    "    history = vae.fit(\n",
    "        X_train, epochs = 50, batch_size = 40,\n",
    "        callbacks = [early_stopping_cb],\n",
    "        validation_data = (X_valid,)\n",
    "    )\n",
    "\n",
    "    # vae.save_weights(os.path.join(model_dir, 'vae.weights.h5')) # save model weights after training\n",
    "    tf.saved_model.save(vae, model_dir + '/model')\n",
    "\n",
    "    hist_pd = pd.DataFrame(history.history)\n",
    "    hist_pd.to_csv(os.path.join(model_dir, f'history_{date}.csv'), index = False)\n",
    "\n",
    "    test_loss = vae.evaluate(X_test)\n",
    "    test_loss = dict(zip([\"loss\", \"reconstruction_loss\", \"kl_loss\"], test_loss))\n",
    "\n",
    "    print('Test loss:', test_loss)\n",
    "\n",
    "    with open(os.path.join(model_dir, f'test_loss_{date}.json'), 'w') as json_file:\n",
    "        json.dump(test_loss, json_file, indent = 4)\n",
    "\n",
    "# used MNIST data preproc as template for this definition\n",
    "def load_data(): \n",
    "    files = os.listdir(data_dir)\n",
    "    files = [f for f in files if '.nc' in f]\n",
    "    \n",
    "    all_data = np.expand_dims(\n",
    "        np.concatenate(\n",
    "            [netCDF4.Dataset(data_dir + converted_file)['msl'][:] for converted_file in files]\n",
    "        ),\n",
    "        -1\n",
    "    ).astype(\"float32\") / 110000\n",
    "    return all_data\n",
    "\n",
    "def run_train(num_files, date, vae):\n",
    "    slp = load_data() # load data\n",
    "    print(\"shape:\", np.shape(slp)) # verify data shape\n",
    "    \n",
    "    # split the data - y values are throw away\n",
    "    X_train, X_test, y_train, y_test = train_test_split(slp[0:(num_files * 80 - 1), :, :, :], np.arange(0, num_files * 80 - 1), test_size = 0.2, random_state = 1)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.25, random_state = 1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    train_model(X_train, X_test, X_valid, date, vae)\n",
    "    remove_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defdd05-1774-4e56-bd64-2f760c004842",
   "metadata": {},
   "source": [
    "# Train the VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6a16c-2ff9-42fe-bdcd-b8a970f88b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "model_dir = './model_dir'\n",
    "\n",
    "os.makedirs(model_dir, exist_ok = True)\n",
    "os.makedirs(model_dir + '/model', exist_ok = True)\n",
    "\n",
    "# build encoder\n",
    "encoder = build_encoder(latent_dim)\n",
    "print(\"Memory usage after building encoder:\", tf.config.experimental.get_memory_info('GPU:0'))\n",
    "\n",
    "# build decoder\n",
    "decoder = build_decoder(latent_dim)\n",
    "print(\"Memory usage after building decoder:\", tf.config.experimental.get_memory_info('GPU:0'))\n",
    "\n",
    "# build VAE (variational autoencoder)\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer = 'rmsprop') \n",
    "# vae.compile(optimizer = keras.optimizers.Adam())\n",
    "print(\"Memory usage after building VAE:\", tf.config.experimental.get_memory_info('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79096d-dee9-4ffc-9279-442e9232f20f",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameter cell for pm \n",
    "year = \"2018\"\n",
    "month = \"01\"\n",
    "day = \"01\"\n",
    "ensembles = [\"c00\", \"p01\", \"p02\", \"p03\", \"p04\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952473d-6ec6-4581-8b49-d6d472b4e0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run training\n",
    "num_files = get_data(year, month, day, ensembles)\n",
    "!csh batch_grib2nc.csh\n",
    "\n",
    "date = year + month + day\n",
    "run_train(num_files, date, vae)\n",
    "    \n",
    "print(\"Memory usage after training:\", tf.config.experimental.get_memory_info('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81905dc-6db8-4b40-868f-39055c747937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvae_env]",
   "language": "python",
   "name": "conda-env-cvae_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
